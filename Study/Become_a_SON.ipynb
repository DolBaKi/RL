{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnv:\n",
    "    def __init__(self):\n",
    "        self.state_space = [(i,j) for i in range(12) for j in range(12)] # 그리드\n",
    "        self.action_space = [(0,1),(1,1),(1,0),(1,-1),(0,-1)] # 5번 슈팅은 따로 뺄거\n",
    "        self.enemy = [\n",
    "            (3,4),\n",
    "            (5,2),\n",
    "            (5,4),\n",
    "            (5,6),\n",
    "            (6,3),\n",
    "            (6,5),\n",
    "            (8,1),\n",
    "            (8,3),\n",
    "            (8,5),\n",
    "            (8,7)\n",
    "        ]\n",
    "\n",
    "    def transition(self, state, action):\n",
    "        node, _ = state\n",
    "        x, y = node\n",
    "        tx, ty = self.action_space[action]\n",
    "        next_node = (x+tx,y+ty)\n",
    "        isEnemy = [0 for _ in range(5)]\n",
    "        for d in self.enemy:\n",
    "            for i in range(5):\n",
    "                x, y = next_node\n",
    "                tx, ty = self.action_space[i]\n",
    "                if (x+tx,y+ty) == d:\n",
    "                    isEnemy[i] = 1\n",
    "\n",
    "        next_state = (next_node,isEnemy)\n",
    "        return next_state\n",
    "\n",
    "    def reward_function(self, state, action):\n",
    "        reward = 0\n",
    "        _, isEnemy = state\n",
    "        if isEnemy[2] == 1:\n",
    "            if action == 1:\n",
    "                reward = 1\n",
    "            if action == 3:\n",
    "                reward = 1\n",
    "        next_state = self.transition(state,action)\n",
    "        node, _ = next_state\n",
    "        x, y = node\n",
    "\n",
    "        if 0 > x or x > 11 or 0 > y or y > 8:\n",
    "            reward = -50\n",
    "\n",
    "        for d in self.enemy:\n",
    "            if node == d:\n",
    "                reward = -50\n",
    "        return reward\n",
    "\n",
    "    def reset(self):\n",
    "        node=(2,4)\n",
    "        isEnemy=[0 for _ in range(5)]\n",
    "        for d in self.enemy:\n",
    "            for i in range(5):\n",
    "                x, y = node\n",
    "                tx, ty = self.action_space[i]\n",
    "                if (x+tx,y+ty) == d:\n",
    "                    isEnemy[i] = 1\n",
    "        state = (node,isEnemy)\n",
    "        self.state = state\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 5:\n",
    "            node, _ = self.state\n",
    "            x,y=node\n",
    "            if x == 9 and 1 < y and y < 7:\n",
    "                return self.state, 50, True\n",
    "            else:\n",
    "                return self.state, 0, True\n",
    "\n",
    "        next_state = self.transition(self.state, action)\n",
    "        reward = self.reward_function(self.state, action)\n",
    "        done = False\n",
    "        if reward == -50:\n",
    "            done = True\n",
    "        self.state=next_state\n",
    "        return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyEnv()\n",
    "state = env.reset()\n",
    "done = False\n",
    "print(\"Initial state:\", state)\n",
    "while not done:\n",
    "    action = int(input(\"Choose action from (0, 1, 2, 3, 4, 5): \"))\n",
    "    print(\"Chose action:\", action)\n",
    "    state, reward, done = env.step(action)\n",
    "    print(\"New state:\", state)\n",
    "    print(\"Reward:\", reward)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
